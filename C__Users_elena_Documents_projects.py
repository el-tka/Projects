#!/usr/bin/env python
# coding: utf-8

# ## Комментарий наставника
# Привет, Елена! Меня зовут Александр и я буду проверять твой проект. Спасибо за твою работу:) Далее по ходу работы я оставлю свои комментарии и предложения. Постарайся их учесть в этом и дальнейших проектах. Комментарии ты можешь найти в текстовой ячейке с заголовком «Комментарий наставника» (как здесь) либо в ячейках с кодом в следующем виде: «#Комментарий наставника: <сам комментарий>». \
# Часть комментариев может быть выделена цветом: \
# <span style="color:green">Зелёный цвет символизирует, что всё отлично</span> \
# <span style="color:orange">Оранжевый цвет символизирует рекомендации</span> \
# <span style="color:red">Красный цвет символизирует недочёты</span>

# ### 1. EDA

# In[2]:


import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


# In[2]:


data = pd.read_csv('/datasets/gym_churn.csv')


# In[3]:


data.head()


# In[4]:


data.info()


# In[5]:


data.shape


# In[6]:


data.duplicated().sum()


# Размер данных составляет 4000 объктов наблюдения. В данных присутствует 14 признаков, в том числе и целевая переменная - факт оттока покупателей на текущий месяц. 7 признаков представлены бинарными значениями и 7 признаков представляют собой числовые данные. Целевая переменная временную структуру не имеет. В данных отсутствуют пропуски и дубликаты.

# ## Комментарий наставника
# <span style="color:green">Хорошо.</span>

# In[7]:


data.describe()


# Проанализировав средние значения и стандартные отклонения числовых признаков, можно заметить, что стандартные отклонения признаков отличаются от 1, кроме признаков средней частоты посещений в неделю за все время с начала действия абонемента и  средней частоты посещений в неделю за предыдущий месяц. Значит для признаков необходимо будет произвести стандартизацию для приведения их к нормальному виду. 

# In[8]:


#разделим признаки на числовые и бинарные
numeric_data = data.drop(columns = ['Churn', 'gender', 'Near_Location', 'Partner', 'Promo_friends', 'Phone',
                                    'Group_visits', 
                                    ])


# In[9]:


bool_data = data[['gender', 'Near_Location', 'Partner', 'Promo_friends', 'Phone', 'Group_visits']]


# In[10]:


#рассчитаем средние значения числовых переменных в зависимости от факта оттока 
numeric_data_by_churn = data.groupby('Churn')[[i for i in numeric_data.columns]].mean().reset_index() 


# In[11]:


numeric_data_by_churn


# In[12]:


#рассчитаем средние значения бинарных переменых в зависимости от факта оттока
bool_data_by_churn = data.groupby('Churn')[[i for i in bool_data.columns]].mean().reset_index() 


# In[13]:


bool_data_by_churn


# In[14]:


#построим гистограммы числовых признаков в зависимости от факта оттока
for col in numeric_data.columns:
    f, axes = plt.subplots(sharex=True)
    sns.distplot(data[data['Churn']==0][col], color='m', bins=30)
    sns.distplot(data[data['Churn']==1][col], ax = axes, bins =30)
    plt.show()


# ## Комментарий наставника
# <span style="color:orange">Графики хорошие, только добавь легенду, чтобы было понятно, какой цвет к какой группе клиентов (оставшихся или ушедших из компании) относится.</span>

# По гистограммам видно что:
# - доля ушедших пользователей тем больше, чем меньше продолжительность абонемента, доля оставшихся пользователей практически равномерно распределена среди длительностей абонементов;
# - среди ушедших пользователей превалируют люди моложе 30 лет, среди оставшихся - люди старше 30 лет;
# - среди ушедших пользователей превалируют люди с суммарными расходами на другие услуги центра менее 150 е.;
# - число ушедших пользователей превышает число оставшихся среди тех, у кого до окончания абонемента оставалось менее 2х месяцев, в районе 5-6 месяцев числоушедших и оставшихся примерно равно, в районе года, число оставшихся превышает число ушедших;
# - число ушедших пользователей превышает число оставшихся среди тех, кто начал посещать центр до 3-х месяцев назад;
# - средняя частота посещений в неделю за все время с начала действия абонемента среди ушедших пользователей превалирует в районе от 1 до 2 раз, среди оставшихся в районе от 1 до 3 раз;
# - средняя частота посещений в неделю за предыдущий месяц у ушедших пользователей превалирует в районе от 0 до 2х раз с большим количеством пользователей, непосещавших центр в предыдущий месяц; у оставшихся пользователей среднее кол-во посещений превалирует в районе от 1,5 раза до 3 раз.

# ## Комментарий наставника
# <span style="color:green">Замечательно!</span>

# In[15]:


#построим гистограммы бинарных признаков в зависимости от факта оттока
for col in bool_data.columns:
    f, axes = plt.subplots(sharex=True)
    sns.distplot(data[data['Churn']==0][col], kde=False, color="r")
    sns.distplot(data[data['Churn']==1][col], kde=False, color="b", ax = axes)
    plt.show()


# По столбчатым диаграммам видно:
# - пол не влияет на отток пользователей;
# - среди пользователей, у кого жилье или работа не находятся рядом с центром доля отвалов более 50%;
# - доля отвалов меньше среди пользователей, пришедших по партнерской программе центра и по программе "приведи друга";
# - наличие телефонного номера не влияет на отвалы;
# - среди пользователей, непосещавших групповые программы, доля отвалов больше.

# ## Комментарий наставника
# <span style="color:green">Всё так.</span>

# In[16]:


sns.pairplot(numeric_data)


# In[17]:


cm = data.corr().round(2)


# In[18]:


plt.figure(figsize = (10,10))
sns.heatmap(cm, annot = True, square=True, center = 0, linewidths=.5)


# ПО распределениям и матрице корреляций мультиколлинеарными признаками являются:
# - средняя частота посещений в неделю за предыдущий месяц и средняя частота посещений в неделю за все время с начала действия абонемента;
# - срок до окончания текущего действующего абонемента (в месяцах) и длительность текущего действующего абонемента (месяц, 3 месяца, 6 месяцев, год).

# #### P.S. Не будем строить совметсное распределение признаков и целевой переменной, тк целевая переменная - бинарная величина

# ## Комментарий наставника
# <span style="color:green">К карте корреляций, как и к первой части работы, вопросов нет. Идём дальше.</span>

# ### 2. Churn model

# In[19]:


#удалим мультиколлинеарные признаки средней частоты посещений в неделю 
#с начала действия абонемента и длительность текущего действующего абонемента (месяц, 3 месяца, 6 месяцев, год)
data.drop('Avg_class_frequency_total', axis = 1, inplace = True) # убираем один из пары коррелирующих признаков
data.drop('Contract_period', axis = 1, inplace = True)


# In[20]:


#разделим данные на матрицу признаков и вектор целевой переменной
y = data['Churn']
X = data.drop(['Churn'], axis = 1)


# In[21]:


#разделим на учебную и валидационную выборки
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)


# In[22]:


#cтандартизируем данные
scaler = StandardScaler()
X_train_st = scaler.fit_transform(X_train) 
X_test_st = scaler.transform(X_test)


# In[23]:


models = [LogisticRegression(random_state = 0), RandomForestClassifier(random_state = 0)]


# In[24]:


def make_prediction(m, X_train, y_train, X_test, y_test):
    model = m
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print('Accuracy:{:.2f} Precision:{:.2f} Recall:{:.2f}'.format(accuracy_score(y_test, y_pred), 
                                                                  precision_score(y_test, y_pred),
                                                                  recall_score(y_test, y_pred)))


# In[25]:


for i in models:
    print(i)
    make_prediction(m=i,X_train = X_train_st, y_train= y_train,
                    X_test=X_test_st, y_test = y_test)


# На основе полученных метрик после оценки моделей логистическая регрессия показывает лучший результат по доле правильных прогнозов (90%), а также по полноте верных прогнозов (82%), а точность прогнозов у моделей одинакова (79%), точность прогнозов является целевой метрикой, т.к. если модель спрогнозирует отток пользователя, который не собирается уходить, дополнительные маркетинговые усилия на конкретного пользователя принесут дополнительные расходы для центра.

# ## Комментарий наставника
# <span style="color:green">Верно.</span>

# In[28]:


#посмотрим все метрики модели
def print_all_metrics(y_true, y_pred, y_proba, title):
    print(title)
    print('\tAccuracy: {:.2f}'.format(accuracy_score(y_true, y_pred)))
    print('\tPrecision: {:.2f}'.format(precision_score(y_true, y_pred)))
    print('\tRecall: {:.2f}'.format(recall_score(y_true, y_pred)))
    print('\tF1: {:.2f}'.format(f1_score(y_true, y_pred)))
    print('\tROC_AUC: {:.2f}'.format(roc_auc_score(y_true, y_proba)))


# In[29]:


lr_model = LogisticRegression(random_state = 0)
lr_model.fit(X_train_st, y_train)
lr_predictions = lr_model.predict(X_test_st)
lr_probabilities = lr_model.predict_proba(X_test_st)[:,1]
print_all_metrics(y_test, lr_predictions, lr_probabilities , title= 'Метрики для модели логистической регрессии:')


# Логистическая регрессия выдает хорошие показатели метрик, модель можно считать успешной.

# In[30]:


#посмотрим на распределение признаков по значимости в модели случайного леса
importances_by_random_forest = pd.DataFrame( data = models[1].feature_importances_, columns =['importance_rate_rf'])


# In[41]:


features = pd.DataFrame(data = X_test.columns.to_list(), columns = ['features'])


# In[43]:


importances_by_random_forest.sort_values(by= 'importance_rate_rf', ascending=False).plot(kind='bar')


# In[32]:


#посмотрим на распределение признаков по значимости в модели логистической регрессии
importances_by_lr = pd.DataFrame( data = abs(lr_model.coef_.T), columns =['importance_rate_lr'])
importances_by_lr.sort_values(by= 'importance_rate_lr', ascending=False).plot(kind='bar')


# In[45]:


pd.DataFrame(data = X_test.columns.to_list(), columns = ['features'])


# В обоих моделях наиболее важными признаками, влияющими на отток пользователей, являются:
# - время с момента первого обращения в фитнес-центр (в месяцах);
# - средняя частота посещений в неделю за предыдущий месяц;
# - возраст;
# - суммарная выручка от других услуг фитнес-центра.
# 
# Модель логистической регрессии ставит на третье по значимости место *срок до окончания текущего действующего абонемента*, тогда как модель случайного леса относит данный признак лишь на пятой по значимости место.

# ## Комментарий наставника
# <span style="color:green">Прекрасная работа с моделями и анализ значимости признаков. Молодец!:)</span> \
# <span style="color:orange">Для нахождения лучшей модели можно было попробовать подобрать гиперпараметры для случайного леса. Реализовать это достаточно просто (с помощью цикла, например, можно попробовать разные значения глубины дерева или разное количество деревьев), а качество модели может значительно улучшиться.</span>

# ### 3. Customers Clasterisation Model

# In[46]:


# произведем кластеризацию пользователей
sc = StandardScaler()
X_sc = sc.fit_transform(X)


# In[47]:


from scipy.cluster.hierarchy import dendrogram, linkage


# In[50]:


#построим матрицу расстояний между объектами
linked = linkage(X_sc, method = 'ward')


# In[51]:


#на основе матрицы расстояний построим дендограмму
plt.figure(figsize=(15, 10))  
dendrogram(linked, orientation='top')
plt.title('Иерархическая кластеризация для фитнес-центра')
plt.show()


# На дендограмме видно, что модель наиболее ярко выделяет 5 основных кластеров пользователей.

# In[64]:


#применим алгоритм к данным и сформируем вектор кластеров
from sklearn.cluster import KMeans
km = KMeans(n_clusters = 5, random_state = 0) 
labels = km.fit_predict(X_sc)


# In[65]:


from sklearn.metrics import silhouette_score

print('Метрика силуэта: {:.2f}'.format(silhouette_score(X_sc, labels)))


# Метрика силуэта показывает небольшое значение, а значит кластеризацию нельзя назвать успешной.

# ## Комментарий наставника
# <span style="color:green">К кластеризации вопросов нет.</span>

# In[53]:


#транспонируем вектор для удобства интерпретации
labels.T.shape


# In[54]:


labels = pd.DataFrame(data = labels.T, columns = ['cluster'])


# In[55]:


data = data.join(labels)


# In[57]:


#найдем средние значения признаков по кластерам
data.groupby('cluster')[[i for i in numeric_data.drop(['Avg_class_frequency_total', 'Contract_period'], axis=1).columns]].mean()


# In[58]:


data.groupby('cluster')[[i for i in bool_data.columns]].mean()


# In[59]:


for col in numeric_data.drop(['Avg_class_frequency_total', 'Contract_period'], axis=1).columns:
    f, axes = plt.subplots(2, 3, figsize=(9, 9), sharex=True)
    sns.distplot(data[data['cluster']==0][col], color="r", ax = axes[0,0])
    sns.distplot(data[data['cluster']==1][col], color="b", ax = axes[0,1])
    sns.distplot(data[data['cluster']==2][col], color="g", ax = axes[0,2])
    sns.distplot(data[data['cluster']==3][col], color="m", ax = axes[1,0])
    sns.distplot(data[data['cluster']==4][col], color="y", ax = axes[1,1])
    plt.show()


# На графиках распределения видно, что:
# - кластеры не практически не отличаются по возрасту;
# - кластеры несущественно различаются по объему трат на доп. услуги фитнес-центра;
# - по сроку до окончания действия абонемента:
#   1. в 0 кластере превалируют новые клиенты со сроком до окончания действия абонемента около года, но также присутствуют и клиенты со сроком около получгода и месяца;
#   2. во 1 и 4 кластерах превалируют клиенты, у кого до окончания абонемента остался месяц, но также причутствуют и клиенты, у кого осталось 6 месяцев или год;
#   3. в 2 и 3 кластерах сильно превалируют клиенты, у кого до окончания абонемента остался месяц;
# - по времени с момента обращения в центр кластеры различаются, в 2 кластере присутствуют клиенты, которые пришли месяц назад; в 3 - 3 месяца назад, в 0 и 4 кластерах - 4 месяца назад, во 1 кластере 5 месяцев назад;
# - по средней посещаемости за последний месяц 1 и 4 кластеры похожи между собой, там средняя посещаемость распределена около 2.5 раз в неделю за последний месяц; 0 и 3 кластеры ходят в зал реже в среднем около 2-х раз в неделю за месяц, 2 кластер либо не ходил в зал за последний месяц, либо ходил менее 1,5  раза в неделю.

# ## Комментарий наставника
# <span style="color:green">Всё здорово, нечего добавить.</span>

# In[66]:


import plotly.graph_objects as go
for col in bool_data.columns:
    x=['нет', 'да']
    clusters = {1: 'first cluster', 2:'second cluster', 3:'third cluster', 4:'fourth cluster'}
    fig = go.Figure(go.Bar(x=x, y= data.query('cluster ==0').groupby(col)[col].count().to_list(), name='zero cluster'))
    for key, value in clusters.items():
        fig.add_trace(go.Bar(x=x, y= data.query('cluster ==@key').groupby(col)[col].count().to_list(), name=value))
    fig.update_layout(barmode='stack', 
                      xaxis=dict(
        title= col,
        titlefont_size=10,
        tickfont_size=10,
    ),)
    fig.show()


# На графиках структуры бинарных признаков по кластерам видно, что:
# - по полу кластеры не различаются;
# - 0,1, 2 и 4 кластеры живут или работают рядом с центром, 3 нет;
# - в 0 кластере пользователи пришли по программе партнерства, в 2 и 4 скорее с программой партнерства не связаны;
# - во всех кластерах преобладают клиенты, непришедшие по программе "приведи друга";
# - во всех кластерах преобладают клиенты с указанными тел. номерами;
# - в 0 кластере 50% посещают групповые занятия, в остальных нет.

# ## Комментарий наставника
# <span style="color:green">Хорошо.</span>

# In[67]:


churn_by_cluster= data.groupby('cluster')['Churn'].count().reset_index().rename(columns={'Churn':'Churn_total'})


# In[68]:


churn_yes_by_cluster = data.query('Churn == 1').groupby('cluster')['Churn'].count().reset_index()


# In[69]:


churn_by_cluster = churn_by_cluster.merge(churn_yes_by_cluster, on ='cluster')


# In[70]:


churn_by_cluster['churn_rate'] = churn_by_cluster['Churn']/churn_by_cluster['Churn_total']


# In[71]:


churn_by_cluster['churn_rate'].sort_values(ascending=False).plot(kind='bar')
plt.legend()
plt.title('Доля оттока пользоватлей по кластерам')


# Наиболее склонны к оттоку 2 и 3 кластеры 

# ## Комментарий наставника
# <span style="color:green">Совершенно верно.</span>

# Таким образом, типичными портретами пользователей фитнес-центра являются:
# - **группа 0**: разные по возрасту и со сроком до конца действия абонемента с среднем около полугода, пришедшие в зал около 4 месяцев назад,посещающие зал около 2-х раз в неделю, живущие рядом или работающие рядом с залом,пришедшие по программе партнерства или "приведи друга", посещающие групповые занятия. Это менеее подверженная оттоку группа;
# - **группа 1**: разные по возрасту и со сроком до конца действия абонемента в среднем около 4 месяцев, пришедшие в зал около 5 месяцев назад,посещающие зал около 2,5 раз в неделю, живущие рядом или работающие рядом с залом. Это наименеее подверженная оттоку группа
# - **группа 2**: разные по возрасту и со сроком до конца действия абонемента в среднем около 2 месяцев, пришедшие в зал около 1.5 месяцев назад,посещающие зал около 1 раза в неделю, живущие рядом или работающие рядом с залом. Это наиболее подверженная оттоку группа;
# - **группа 3**:  разные по возрасту и со сроком до конца действия абонемента в среднем около 3 месяцев, пришедшие в зал около 3 месяцев назад,посещающие зал около 1.5 раза в неделю, неживущие рядом и неработающие рядом с залом. Это более подверженная оттоку группа;
# - **группа 4**: разные по возрасту и со сроком до конца действия абонемента в среднем около 5 месяцев, пришедшие в зал около 5 месяцев назад,посещающие зал около 2 раз в неделю, живущие рядом или работающие рядом с залом. Это более менее подверженная оттоку группа.

# В обоих моделях наиболее важными признаками, влияющими на отток пользователей, являются:
# - время с момента первого обращения в фитнес-центр (в месяцах);
# - средняя частота посещений в неделю за предыдущий месяц;
# - срок до окончания текущего абонемента.

# ## Комментарий наставника
# <span style="color:green">Согласен с выводами.</span>

# Наиболее подвержены риску отвала пользователи второй и третьей группы. 
# 
# Для работы с данными пользователями порекомендую направить маркетинговые усилия на продление абонемента пользователей за 2-3 месяца до конца абонемента путем скидок и спец предложений на доп. услуги фитнес-центра, ведь пользователи с большими средними расходами на доп услуги реже уходят.
# 
# Также порекомендую стимулировать пользователей данных групп на посещение групповых занятий а также на увеличение частоты посещения фитнес-центра также путем скидок и спец предложений на доп. услуги фитнес-центра или путем предолставления права на посещение одного или некольких групповых занятий бесплатно. 
# 
# Отличным вектором работы с пользователями будет стимулирование использования рефереальной программы, а также расширение списка партнеров центра среди предприятий, тк такие пользователи менее подвержены оттоку.

# ## Итоговый комментарий наставника
# <span style="color:blue">Рекомендации правильные и обоснованные исследованием. \
# Вопросов к проекту нет, зачтено. Поздравляю и желаю успехов!:)</span>
